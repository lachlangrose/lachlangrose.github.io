{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nProbabilistic faulted folds\n===========================\nImports\n~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from LoopStructural import GeologicalModel\nfrom LoopStructural.visualisation import LavaVuModelViewer\nfrom LoopStructural.datasets import load_intrusion\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n# %matplotlib inline\n# %load_ext snakeviz\n\ndata, bb = load_intrusion()\n\nfault_data = data[data['type']=='fault']\n\nfault_data\n\nmodel = GeologicalModel(bb[0,:],bb[1,:])\nmodel.set_model_data(fault_data)\nfault = model.create_and_add_fault('fault',\n                                   -600,\n                                   nelements=2000,\n                                   steps=4,\n                                   interpolatortype='PLI',\n                                  buffer=0.3\n                                  )\n\n\nbedding_val = np.random.random((40,4))\nbedding_val[:,0]*=bb[1,0]\nbedding_val[:,1]*=bb[1,1]\nbedding_val[:,2]=-600\nbedding_val[:,3]=0\nbedding_val = np.vstack([bedding_val,bedding_val])\nbedding_val[40:,2]-=-500\nbedding_val[40:,3]= -1\n# print(bedding_val)\n# print(fault['feature'].evaluate(model.scale(bedding_val)))\nbedding_val[:,:3] = model.rescale(fault['feature'].apply_to_points(model.scale(bedding_val[:,:3])))\n\n# print(bedding_val)\n\nnew_data = pd.DataFrame(bedding_val,columns=['X','Y','Z','val'])\nnew_data['type'] = 'strati'\n# new_data['val'] = 0\n\n# normal_vec = pd.DataFrame([[9000,10,10,0,0,1]],columns=['X','Y','Z','nx','ny','nz'])\n# normal_vec['type'] = 'strati'\n\ndata = pd.concat([fault_data,new_data],sort=False)\ndata\n\ndef planeFit(points):\n    \"\"\"\n    p, n = planeFit(points)\n\n    Given an array, points, of shape (d,...)\n    representing points in d-dimensional space,\n    fit an d-dimensional plane to the points.\n    Return a point, p, on the plane (the point-cloud centroid),\n    and the normal, n.\n    \"\"\"\n    import numpy as np\n    from numpy.linalg import svd\n    #points = points.T\n    #print('p',points.shape)\n#     points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n    ctr = points.mean(axis=1)\n    x = points - ctr[:,np.newaxis]\n    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n    U,S,V = svd(M)\n    normal = V[-1]\n    d = -np.sum(normal*ctr)\n    return np.hstack([normal,[d]])\n\ndef planeDistance(points):\n    params = planeFit(points)\n    a, b, c, d = params\n    x, y, z = points\n    length = np.sqrt(a**2 + b**2 + c**2)\n    return (np.abs(a * x + b * y + c * z + d) / length).mean()\n\n\n\nimport emcee\n\ndef log_prior(theta):\n    displacement, sigma2 = theta\n    mu = 600\n    sigma = 100\n    if sigma <= 0:\n        return -np.inf\n    if mu <= 0:\n        return -np.inf\n    if sigma2 <= 0:\n        return -np.inf\n    return -np.log(1.0/(np.sqrt(2*np.pi)*sigma))-0.5*(displacement-mu)**2/sigma**2 - np.log(sigma) - np.log(mu) - np.log(sigma2)\n\n#import dill as pickle\n\nmodel = GeologicalModel(bb[0,:],bb[1,:],reuse_supports=True)\nmodel.set_model_data(data)\nfault = model.create_and_add_fault('fault',\n                                   10,\n                                   nelements=2000,\n                                   steps=1,\n                                   interpolatortype='PLI',\n                                  buffer=0.8,\n                                   solver='pyamg'\n                                  )\ndef log_likelihood(theta):\n    displacement, sigma2 = theta\n#     print(\"displacement: {}\".format(displacement))\n    fault['feature'].set_displacement(displacement)\n\n    #strati['feature'].get_interpolator().data_added = False\n    strati = model.create_and_add_foliation('strati',\n                                            nelements=2000,\n                                            interpolatortype='PLI',\n                                            cgw=0.1,\n                                            solver='fake',\n                                            buffer=1\n                                           )\n    strati['feature'].builder.add_data_to_interpolator()\n    points = strati['feature'].get_interpolator().get_value_constraints()[:,:4]\n    unique_values = np.unique(points[:,3])\n    distance = np.zeros_like(unique_values).astype(float)\n    for i, u in enumerate(unique_values):\n        distance[i] = planeDistance(points[points[:,3] == u,:3].T)\n    \n#     print(np.sum(distance*model.scale_factor))    \n#     plt.hist(strati['feature'].evaluate_value_misfit())\n    n = len(distance)#strati['feature'].interpolator.get_value_constraints()[:,:3].shape[0]\n    log_like = -0.5 * np.sum(np.log(2 * np.pi * sigma2 ** 2) + (0 - model.scale_factor*distance) ** 2 / sigma2 ** 2)\n    #data_added = False\n\n#     sigma2 = 3\n#     log_like = -(n/2)*np.log(2*np.pi) - (n/2)*np.log(sigma2)\n#     log_like-= (1/(2*sigma2))*np.sum(np.abs(strati['feature'].evaluate_value_misfit())**2)\n    \n#     sigma2 = strati['feature'].evaluate_value(strati['feature'].interpolator.get_value_constraints()[:,:3]) ** 2 \n#     log_like = -0.5 * np.sum((strati['feature'].evaluate_value_misfit()) ** 2 / sigma2 + np.log(sigma2))\n#     print(\"log likelihood {}\".format(log_like))\n#     print(\"missfit {}\".format(np.sum(strati['feature'].evaluate_value_misfit())))\n    if ~np.isfinite(log_like):\n        return -np.inf\n#     pickle.dump(model,open(\"models/model2_sigma_{}_mu_{}_displacement_{}.pkl\".format(sigma,mu,displacement),\"wb\"))\n    return log_like                         \n\n\ndef log_probability(theta):\n    lp = log_prior(theta)\n    if not np.isfinite(lp):\n        return -np.inf\n    ll = log_likelihood(theta)\n    return lp + log_likelihood(theta)\n\nimport emcee\nstart = np.array([600,0])\npos = start + np.array([1e3,6e2]) * np.random.randn(50, 2)\npos[:,1:] = np.abs(pos[:,1:])\nnwalkers, ndim = pos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability)\nsampler.run_mcmc(pos, 200, progress=True,tune=True)\n\nflat_samples = sampler.get_chain(discard=40, flat=True,thin=10)\n\nplt.hist(flat_samples[:,0])\n\nlabels=['Fault displacement', 'sigma']\n\nimport corner\nflat_samples.shape\nfig = corner.corner(\n    flat_samples,\n    labels=labels\n);\n\nplt.plot(sampler.get_chain(flat=True)[:,0])\n\nchain = sampler.get_chain()\n\nchain.shape\n\nfor i in range(20):\n    plt.plot(chain[:,i,0])\n\nfor i in range(20):\n    plt.plot(chain[:,i,2])\n\n\n\nflat_samples[:,0]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}